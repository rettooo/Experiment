"""
ì„ë² ë”© ìºì‹œ ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import argparse
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from utils.embedding_cache import embedding_cache
from utils.document_cache import document_cache
from utils.env_loader import load_env


def main():
    parser = argparse.ArgumentParser(description="ì„ë² ë”© ìºì‹œ ê´€ë¦¬")
    subparsers = parser.add_subparsers(dest="command", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´")

    # list ëª…ë ¹ì–´
    list_parser = subparsers.add_parser("list", help="ìºì‹œ ëª©ë¡ ì¡°íšŒ")

    # stats ëª…ë ¹ì–´
    stats_parser = subparsers.add_parser("stats", help="ìºì‹œ í†µê³„ ì¶œë ¥")

    # delete ëª…ë ¹ì–´
    delete_parser = subparsers.add_parser("delete", help="ìºì‹œ ì‚­ì œ")
    delete_parser.add_argument("cache_key", help="ì‚­ì œí•  ìºì‹œ í‚¤")

    # info ëª…ë ¹ì–´
    info_parser = subparsers.add_parser("info", help="íŠ¹ì • ìºì‹œ ì •ë³´ ì¡°íšŒ")
    info_parser.add_argument("cache_key", help="ì¡°íšŒí•  ìºì‹œ í‚¤")

    # clear ëª…ë ¹ì–´
    clear_parser = subparsers.add_parser("clear", help="ëª¨ë“  ìºì‹œ ì‚­ì œ")
    clear_parser.add_argument("--confirm", action="store_true", help="ì‚­ì œ í™•ì¸")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ìºì‹œ ì¡°íšŒì—ëŠ” ë¶ˆí•„ìš”í•˜ì§€ë§Œ ì¼ê´€ì„±ì„ ìœ„í•´)
    load_env()

    if args.command == "list":
        list_caches()
    elif args.command == "stats":
        embedding_cache.print_cache_stats()
    elif args.command == "delete":
        delete_cache(args.cache_key)
    elif args.command == "info":
        show_cache_info(args.cache_key)
    elif args.command == "clear":
        clear_all_caches(args.confirm)


def list_caches():
    """ìºì‹œ ëª©ë¡ ì¶œë ¥"""
    # ì„ë² ë”© ìºì‹œ
    embedding_caches = embedding_cache.list_caches()

    # ë¬¸ì„œ ìºì‹œ
    document_caches = document_cache.list_caches()

    if not embedding_caches and not document_caches:
        print("ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì„ë² ë”© ìºì‹œ
    if embedding_caches:
        print("\nğŸ“¦ ì„ë² ë”© ìºì‹œ ëª©ë¡")
        print("=" * 80)
        print(
            f"{'ìºì‹œ í‚¤':<40} {'ë¬¸ì„œ ìˆ˜':<10} {'ì°¨ì›':<10} {'í¬ê¸°(MB)':<10} {'ìƒì„±ì¼'}"
        )
        print("-" * 80)

        for cache_info in embedding_caches:
            cache_key = cache_info["cache_key"]
            metadata = cache_info["metadata"]
            size_mb = embedding_cache.get_cache_size(cache_key) / 1024 / 1024

            print(
                f"{cache_key:<40} "
                f"{metadata['document_count']:<10} "
                f"{metadata['embedding_dimension']:<10} "
                f"{size_mb:<10.2f} "
                f"{metadata['created_at'][:19]}"
            )

    # ë¬¸ì„œ ìºì‹œ
    if document_caches:
        print("\nğŸ“„ ë¬¸ì„œ ìºì‹œ ëª©ë¡")
        print("=" * 80)
        print(f"{'ìºì‹œ í‚¤':<40} {'ë¬¸ì„œ ìˆ˜':<10} {'S3 Bucket':<20}")
        print("-" * 80)

        for cache_info in document_caches:
            cache_key = cache_info["cache_key"]
            doc_count = cache_info["document_count"]
            s3_bucket = cache_info["s3_config"]["s3_bucket"]

            print(f"{cache_key:<40} " f"{doc_count:<10} " f"{s3_bucket:<20}")


def delete_cache(cache_key: str):
    """íŠ¹ì • ìºì‹œ ì‚­ì œ"""
    if not embedding_cache.exists(cache_key):
        print(f"âŒ ìºì‹œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {cache_key}")
        return

    # ì‚­ì œ í™•ì¸
    response = input(f"ì •ë§ë¡œ '{cache_key}' ìºì‹œë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if response.lower() != "y":
        print("ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    if embedding_cache.delete_cache(cache_key):
        print(f"âœ… ìºì‹œ ì‚­ì œ ì™„ë£Œ: {cache_key}")
    else:
        print(f"âŒ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {cache_key}")


def show_cache_info(cache_key: str):
    """íŠ¹ì • ìºì‹œ ìƒì„¸ ì •ë³´ ì¶œë ¥"""
    if not embedding_cache.exists(cache_key):
        print(f"âŒ ìºì‹œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {cache_key}")
        return

    metadata = embedding_cache.get_metadata(cache_key)
    size_mb = embedding_cache.get_cache_size(cache_key) / 1024 / 1024

    print(f"\nğŸ“¦ ìºì‹œ ì •ë³´: {cache_key}")
    print("=" * 60)
    print(f"ë¬¸ì„œ ìˆ˜: {metadata['document_count']}")
    print(f"ì„ë² ë”© ì°¨ì›: {metadata['embedding_dimension']}")
    print(f"í¬ê¸°: {size_mb:.2f} MB")
    print(f"ìƒì„±ì¼: {metadata['created_at']}")
    print(f"ì €ì¥ ê²½ë¡œ: {embedding_cache.get_cache_path(cache_key)}")

    if "embedder_config" in metadata.get("additional_info", {}):
        print(f"\nì„ë² ë”© ì„¤ì •:")
        embedder_config = metadata["additional_info"]["embedder_config"]
        for key, value in embedder_config.items():
            print(f"  {key}: {value}")

    if "chunker_config" in metadata.get("additional_info", {}):
        print(f"\nì²­í‚¹ ì„¤ì •:")
        chunker_config = metadata["additional_info"]["chunker_config"]
        for key, value in chunker_config.items():
            print(f"  {key}: {value}")


def clear_all_caches(confirm: bool = False):
    """ëª¨ë“  ìºì‹œ ì‚­ì œ"""
    caches = embedding_cache.list_caches()

    if not caches:
        print("ì‚­ì œí•  ìºì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if not confirm:
        print(f"âš ï¸  {len(caches)}ê°œì˜ ìºì‹œê°€ ì‚­ì œë©ë‹ˆë‹¤:")
        for cache_info in caches:
            print(f"  - {cache_info['cache_key']}")

        response = input("\nì •ë§ë¡œ ëª¨ë“  ìºì‹œë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != "y":
            print("ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

    deleted_count = 0
    for cache_info in caches:
        cache_key = cache_info["cache_key"]
        if embedding_cache.delete_cache(cache_key):
            deleted_count += 1

    print(f"âœ… {deleted_count}ê°œ ìºì‹œ ì‚­ì œ ì™„ë£Œ")


if __name__ == "__main__":
    main()
