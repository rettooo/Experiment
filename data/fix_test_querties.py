"""GT Analysis CSV -> 5ê°œì˜ ì •ë‹µ ë°ì´í„°ë¡œ ë¬¶ê¸°"""

import csv
import json
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Any


# GT csv ë¡œë“œí•˜ê³  gt_idë³„ë¡œ ê·¸ë£¹í™”í•˜ê¸°
def load_gt_csv(csv_path: str) -> Dict[str, Dict[str, Any]]:
    grouped_data = defaultdict(
        lambda: {
            "query": None,
            "ground_truth_docs": [],
            "user_profile": {},
            "metadata": {},
        }
    )
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)

        for row in reader:
            gt_id = row.get("GT_ID", "").strip()
            if not gt_id:
                continue

            # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ (ì²« ë²ˆì§¸ í–‰ì—ì„œë§Œ ê°€ì ¸ì˜¤ê¸°)
            if grouped_data[gt_id]["query"] is None:
                query_text = row.get("ì™„ì „í•œ_ê²€ìƒ‰_ì¿¼ë¦¬", "").strip()
                grouped_data[gt_id]["query"] = query_text

                # ì‚¬ìš©ì í”„ë¡œí•„ íŒŒì‹±
                major = row.get("í•™ìƒ_ì „ê³µ", "").strip()
                interest_job = row.get("í•™ìƒ_ê´€ì‹¬ë¶„ì•¼", "").strip()
                courses = row.get("ìˆ˜ê°•ê³¼ëª©", "").strip()

                grouped_data[gt_id]["user_profile"] = {
                    "major": major if major else None,
                    "interest_job": interest_job.split(", ") if interest_job else [],
                    "courses": courses.split(", ") if courses else [],
                    "certification": [],
                    "club_activities": [],
                }

                # ë©”íƒ€ë°ì´í„°
                grouped_data[gt_id]["metadata"]["gt_id"] = gt_id
                grouped_data[gt_id]["metadata"]["alternative_query"] = row.get(
                    "í•™ìƒ_ì§ˆë¬¸", ""
                ).strip()

            # Ground truth ë¬¸ì„œ ì¶”ê°€ (URLì—ì„œ rec_idx ì¶”ì¶œ)
            url = row.get("URL", "").strip()

            if url and url.startswith("http"):
                # URLì—ì„œ rec_idx ì¶”ì¶œ
                if "rec_idx=" in url:
                    rec_idx = url.split("rec_idx=")[-1].split("&")[0]
                    grouped_data[gt_id]["ground_truth_docs"].append(rec_idx)
                else:
                    print(
                        f"âš ï¸  GT_ID {gt_id}: rec_idxë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” URL: {url[:50]}..."
                    )

            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (ì²« ë²ˆì§¸ ê³µê³  ì •ë³´ë§Œ, URL ì œì™¸)
            if "company_name" not in grouped_data[gt_id]["metadata"]:
                grouped_data[gt_id]["metadata"]["company_name"] = row.get(
                    "íšŒì‚¬ëª…", ""
                ).strip()
                grouped_data[gt_id]["metadata"]["job_title"] = row.get(
                    "ê³µê³ _ì œëª©", ""
                ).strip()

    return dict(grouped_data)


def convert_to_jsonl(grouped_data: Dict[str, Dict[str, Any]], output_path: str):
    """ê·¸ë£¹í™”ëœ ë°ì´í„°ë¥¼ JSONLë¡œ ì €ì¥"""
    with open(output_path, "w", encoding="utf-8") as f:
        for gt_id, data in sorted(
            grouped_data.items(), key=lambda x: int(x[0]) if x[0].isdigit() else 0
        ):
            # ì •ë‹µì´ ì—†ëŠ” ì¿¼ë¦¬ëŠ” ì œì™¸
            if not data["ground_truth_docs"]:
                print(f"âš ï¸  GT_ID {gt_id}: ì •ë‹µ ë¬¸ì„œ ì—†ìŒ, ì œì™¸")
                continue

            # ì¿¼ë¦¬ê°€ ì—†ëŠ” ê²½ìš° ì œì™¸
            if not data["query"]:
                print(f"âš ï¸  GT_ID {gt_id}: ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì—†ìŒ, ì œì™¸")
                continue

            # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
            entry = {
                "query": data["query"],
                "ground_truth_docs": data["ground_truth_docs"],
                "user_profile": data["user_profile"],
                "metadata": data["metadata"],
            }

            f.write(json.dumps(entry, ensure_ascii=False) + "\n")


def validate_jsonl(jsonl_path: str):
    """ìƒì„±ëœ JSONL íŒŒì¼ ê²€ì¦"""

    print(f"\n{'='*60}")
    print(f"ğŸ“Š JSONL íŒŒì¼ ê²€ì¦: {jsonl_path}")
    print(f"{'='*60}")

    total_queries = 0
    total_gt_docs = 0
    gt_doc_counts = []

    with open(jsonl_path, "r", encoding="utf-8") as f:
        for i, line in enumerate(f, 1):
            entry = json.loads(line)
            total_queries += 1
            gt_count = len(entry["ground_truth_docs"])
            total_gt_docs += gt_count
            gt_doc_counts.append(gt_count)

            # ì²« 3ê°œ ìƒ˜í”Œ ì¶œë ¥
            if i <= 3:
                print(f"\n[ì¿¼ë¦¬ {i}]")
                print(f"  GT_ID: {entry['metadata']['gt_id']}")
                print(f"  ì¿¼ë¦¬ ê¸¸ì´: {len(entry['query'])} ì")
                print(f"  ì •ë‹µ ë¬¸ì„œ ìˆ˜: {gt_count}")
                print(f"  ì •ë‹µ ë¬¸ì„œ IDs: {entry['ground_truth_docs'][:3]}...")
                print(f"  íšŒì‚¬ëª…: {entry['metadata'].get('company_name', 'N/A')}")
                print(
                    f"  ê³µê³  ì œëª©: {entry['metadata'].get('job_title', 'N/A')[:50]}..."
                )
                print(f"  ì „ê³µ: {entry['user_profile']['major']}")

    avg_gt_docs = total_gt_docs / total_queries if total_queries > 0 else 0
    min_gt = min(gt_doc_counts) if gt_doc_counts else 0
    max_gt = max(gt_doc_counts) if gt_doc_counts else 0

    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ í†µê³„")
    print(f"{'='*60}")
    print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {total_queries}")
    print(f"ì´ ì •ë‹µ ë¬¸ì„œ ìˆ˜: {total_gt_docs}")
    print(f"í‰ê·  ì •ë‹µ ë¬¸ì„œ/ì¿¼ë¦¬: {avg_gt_docs:.2f}")
    print(f"ìµœì†Œ ì •ë‹µ ë¬¸ì„œ: {min_gt}")
    print(f"ìµœëŒ€ ì •ë‹µ ë¬¸ì„œ: {max_gt}")

    # ì •ë‹µ ê°œìˆ˜ë³„ ë¶„í¬
    from collections import Counter

    dist = Counter(gt_doc_counts)
    print(f"\nì •ë‹µ ë¬¸ì„œ ê°œìˆ˜ ë¶„í¬:")
    for count, freq in sorted(dist.items()):
        print(f"  {count}ê°œ ì •ë‹µ: {freq}ê°œ ì¿¼ë¦¬ ({freq/total_queries*100:.1f}%)")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    csv_path = "Experiment/data/GT Analysis v3.0 2025-08-25.csv"
    output_path = "Experiment/data/test_queries_fixed_v2.jsonl"

    print(f"{'='*60}")
    print(f"GT CSV â†’ JSONL ë³€í™˜ (URL ì œì™¸ ë²„ì „)")
    print(f"{'='*60}")
    print(f"ì…ë ¥: {csv_path}")
    print(f"ì¶œë ¥: {output_path}")

    # 1. CSV ë¡œë“œ ë° ê·¸ë£¹í™”
    print(f"\n1ï¸âƒ£  CSV ë¡œë“œ ë° GT_IDë³„ ê·¸ë£¹í™”...")
    grouped_data = load_gt_csv(csv_path)
    print(f"   âœ… {len(grouped_data)}ê°œ ê³ ìœ  ì¿¼ë¦¬ ë¡œë“œ ì™„ë£Œ")

    # 2. JSONLë¡œ ë³€í™˜
    print(f"\n2ï¸âƒ£  JSONL ë³€í™˜ ì¤‘...")
    convert_to_jsonl(grouped_data, output_path)
    print(f"   âœ… {output_path} ìƒì„± ì™„ë£Œ")

    # 3. ê²€ì¦
    print(f"\n3ï¸âƒ£  ìƒì„±ëœ íŒŒì¼ ê²€ì¦...")
    validate_jsonl(output_path)

    print(f"\n{'='*60}")
    print(f"âœ… ë³€í™˜ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ìƒˆ íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”:")
    print(f"  mv data/test_queries_fixed.jsonl data/test_queries_fixed_old.jsonl")
    print(f"  mv data/test_queries_fixed_v2.jsonl data/test_queries_fixed.jsonl")


if __name__ == "__main__":
    main()
