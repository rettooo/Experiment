"""
JSONL
í‰ê°€ìš© ë°ì´í„° ìƒì„±

ë¶„ì„ìš©
GT Analysis CSV
- queries.csv: ì…ë ¥ìš© ì¿¼ë¦¬ ë°ì´í„°
- ground_truth.csv: ì •ë‹µ ë¹„êµìš© ë°ì´í„°
"""

import csv
import json
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Any


# urlì—ì„œ rec_idx ì¶”ì¶œí•˜ê¸°
def extract_rec_idx_from_url(url: str) -> str:
    if not url or not url.startswith("http"):
        return ""

    if "rec_idx=" in url:
        rec_idx = url.split("rec_idx=")[-1].split("&")[0]
        return rec_idx
    return ""


def load_grouped_data(csv_path: str) -> Dict[str, Dict[str, Any]]:
    """
    GT Analysis CSVë¥¼ ë¡œë“œí•˜ê³  query_idë³„ë¡œ ê·¸ë£¹í™”

    Returns:
        {
            "437": {
                "query_text": "ì „ê³µ: ìƒëª…ê³µí•™...",

                "ground_truths": [
                    {"rec_idx": "50436465", "job_title": "...", "url": "..."},
                    {"rec_idx": "50436592", "job_title": "...", "url": "..."},
                ]
            }
        }
    """
    print(f"\nğŸ“– CSV ë¡œë“œ ì¤‘: {Path(csv_path).name}")
    grouped_data = defaultdict(lambda: {"query_text": "", "ground_truth": []})
    total_rows, skipped_rows = 0, 0

    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            total_rows += 1
            query_id = row.get("GT_ID", "").strip()
            if not query_id:
                skipped_rows += 1
                continue
            # Query Text : ì²« ë“±ì¥ì‹œ
            if not grouped_data[query_id]["query_text"]:
                query_text = row.get("ì™„ì „í•œ_ê²€ìƒ‰_ì¿¼ë¦¬", "").strip()
                if not query_text:
                    skipped_rows += 1
                    continue
                grouped_data[query_id]["query_text"] = query_text
            # Ground Truth : URLì—ì„œ rec_idx ì¶”ì¶œ
            url = row.get("URL", "").strip()
            if url:
                rec_idx = extract_rec_idx_from_url(url)
                if rec_idx:
                    gt_doc = {
                        "rec_idx": rec_idx,
                        "job_title": row.get("ê³µê³ _ì œëª©", "").strip(),
                        "url": url,
                    }
                    if not any(
                        doc["rec_idx"] == rec_idx
                        for doc in grouped_data[query_id]["ground_truth"]
                    ):
                        grouped_data[query_id]["ground_truth"].append(gt_doc)
    print(f"âœ… ì´ {total_rows}ê°œ í–‰ ì²˜ë¦¬ ì™„ë£Œ, {skipped_rows}ê°œ í–‰ ê±´ë„ˆëœ€")
    print(f" - ê³ ìœ  ì¿¼ë¦¬: {len(grouped_data)}ê°œ")

    return dict(grouped_data)


def save_to_jsonl(data: Dict[str, Dict[str, Any]], output_path: str):
    # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print(f"ğŸ“ í‰ê°€ìš© ë°ì´í„° ì €ì¥: {Path(output_path).name}")
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    total_queries = len(data)
    total_gt = 0

    with open(output_file, "w", encoding="utf-8") as f:
        for query_id, query_data in sorted(
            data.items(), key=lambda x: int(x[0]) if x[0].isdigit() else 0
        ):
            query_data = data[query_id]

            output_entry = {
                "query_id": query_id,
                "query_text": query_data["query_text"],
                "ground_truth": query_data["ground_truth"],
            }
            f.write(json.dumps(output_entry, ensure_ascii=False) + "\n")
            total_gt += len(query_data["ground_truth"])
    print(f"âœ… ì´ {total_queries}ê°œ ì¿¼ë¦¬, {total_gt}ê°œ ì •ë‹µ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")

    print(f" - í‰ê·  ì •ë‹µ ë¬¸ì„œ/ì¿¼ë¦¬: {total_gt/total_queries:.2f}")


def main():
    # CSV íŒŒì¼ ê²½ë¡œ
    base_path = (
        "/Users/haing/Desktop/ğŸ«2025-1/ì¡¸ì—… í”„ë¡œì íŠ¸ /fork-experiment/Experiment/data"
    )
    csv_path = f"{base_path}/GT Analysis v3.0 2025-08-25.csv"
    output_jsonl = f"{base_path}/evaluation_queries.jsonl"

    print(f"{'='*60}")
    print(f"GT Analysis CSV â†’ í‰ê°€ìš© ë°ì´í„° ë³€í™˜")
    print(f"{'='*60}")
    print(f"ì…ë ¥: {Path(csv_path).name}")
    print(f"ì¶œë ¥: {Path(output_jsonl).name}")

    # 1. CSV ë¡œë“œ ë° ê·¸ë£¹í™”
    print(f"\n1ï¸âƒ£ CSV ë¡œë“œ ë° ê·¸ë£¹í™”...")
    grouped_data = load_grouped_data(csv_path)

    if not grouped_data:
        print(f"âŒ ì¿¼ë¦¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return

    save_to_jsonl(grouped_data, output_jsonl)

    print(f"\n{'='*60}")
    print(f"âœ… ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"ğŸ“ íŒŒì¼: {output_jsonl}")
    print(f"\nğŸ“Š í™•ì¸:")
    print(f"  wc -l {output_jsonl}")
    print(f"  head -1 {output_jsonl} | jq .")


if __name__ == "__main__":
    main()
