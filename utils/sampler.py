"""
ê³ ìœ  í”„ë¡œí•„ ê¸°ë°˜ ì¿¼ë¦¬ ìƒ˜í”Œë§

ì „ì²´ test_queries ì¤‘ì—ì„œ ê³ ìœ í•œ í”„ë¡œí•„(í•´ì‹œ ê¸°ë°˜)ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡
ì„œë¡œ ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê°ê° 1ê°œì”© ìƒ˜í”Œë§í•˜ëŠ” ë¡œì§
"""

import json
import random
import hashlib
from typing import List, Dict, Any, Optional
from collections import defaultdict


class StratifiedSampler:
    """ê³ ìœ  í”„ë¡œí•„ í•´ì‹œ ê¸°ë°˜ ìƒ˜í”Œë§ì„ í†µí•œ ëŒ€í‘œì„± ìˆëŠ” ì¿¼ë¦¬ ì„ íƒ"""

    def __init__(self, seed: Optional[int] = None):
        """
        Args:
            seed: ì¬í˜„ ê°€ëŠ¥í•œ ìƒ˜í”Œë§ì„ ìœ„í•œ ì‹œë“œê°’
        """
        self.seed = seed
        if seed is not None:
            random.seed(seed)

    def _generate_profile_hash(self, user_profile: Dict[str, Any]) -> str:
        """
        í”„ë¡œí•„ ì „ì²´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  í•´ì‹œ ìƒì„±

        Args:
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„ ë”•ì…”ë„ˆë¦¬

        Returns:
            8ìë¦¬ í•´ì‹œ ë¬¸ìì—´ (ê³ ìœ  í”„ë¡œí•„ ì‹ë³„ì)
        """
        # í”„ë¡œí•„ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì •ë ¬ëœ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        profile_str = json.dumps(user_profile, sort_keys=True, ensure_ascii=False)

        # MD5 í•´ì‹œ ìƒì„± í›„ ì²« 8ìë¦¬ ì‚¬ìš©
        hash_object = hashlib.md5(profile_str.encode('utf-8'))
        return hash_object.hexdigest()[:8]

    def sample_queries(
        self,
        all_queries: List[Dict[str, Any]],
        sample_size: int = 15,
        strategy: str = "profile_based"
    ) -> List[Dict[str, Any]]:
        """
        ì¿¼ë¦¬ ìƒ˜í”Œë§ ìˆ˜í–‰

        Args:
            all_queries: ì „ì²´ ì¿¼ë¦¬ ëª©ë¡
            sample_size: ìƒ˜í”Œ í¬ê¸° (ê³ ìœ  í”„ë¡œí•„ ìˆ˜)
            strategy: ìƒ˜í”Œë§ ì „ëµ ("profile_based", "random")

        Returns:
            ìƒ˜í”Œë§ëœ ì¿¼ë¦¬ ëª©ë¡ (ê° ê³ ìœ  í”„ë¡œí•„ì—ì„œ 1ê°œì”©)
        """

        print(f"ğŸ¯ ìƒ˜í”Œë§ ì‹œì‘: {len(all_queries)}ê°œ ì¤‘ {sample_size}ê°œ ì„ íƒ (ì „ëµ: {strategy})")

        if len(all_queries) <= sample_size:
            print(f"âš ï¸  ì „ì²´ ì¿¼ë¦¬ê°€ ìƒ˜í”Œ í¬ê¸°ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤. ì „ì²´ ì¿¼ë¦¬ ì‚¬ìš©.")
            return all_queries

        if strategy == "profile_based":
            return self._profile_based_sampling(all_queries, sample_size)
        elif strategy == "random":
            return self._random_sampling(all_queries, sample_size)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìƒ˜í”Œë§ ì „ëµ: {strategy}. ì§€ì›ë˜ëŠ” ì „ëµ: profile_based, random")

    def _profile_based_sampling(self, queries: List[Dict[str, Any]], sample_size: int) -> List[Dict[str, Any]]:
        """
        í”„ë¡œí•„ ê¸°ë°˜ ìƒ˜í”Œë§: ê³ ìœ í•œ í”„ë¡œí•„ì´ ê²¹ì¹˜ì§€ ì•Šê²Œ ì„ íƒ
        ê° ê³ ìœ  í”„ë¡œí•„ì—ì„œ 1ê°œ ì¿¼ë¦¬ë§Œ ì„ íƒí•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í‰ê°€
        """

        # 1. í”„ë¡œí•„ í•´ì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  í”„ë¡œí•„ë³„ ì¿¼ë¦¬ ê·¸ë£¹í™”
        profile_groups = defaultdict(list)
        for query in queries:
            user_profile = query.get('user_profile', {})
            profile_hash = self._generate_profile_hash(user_profile)
            profile_groups[profile_hash].append(query)

        print(f"ğŸ“Š ê³ ìœ  í”„ë¡œí•„ë³„ ì¿¼ë¦¬ ë¶„í¬:")
        profile_info = {}
        for profile_hash, profile_queries in profile_groups.items():
            # ê° í”„ë¡œí•„ì˜ ì „ê³µ ì •ë³´ í‘œì‹œ (í•´ì‹œ ëŒ€ì‹ )
            first_query = profile_queries[0]
            major = first_query.get('user_profile', {}).get('major', 'unknown')
            profile_info[profile_hash] = {
                'major': major,
                'query_count': len(profile_queries)
            }
            print(f"  {profile_hash} ({major}): {len(profile_queries)}ê°œ")

        # 2. ì‚¬ìš© ê°€ëŠ¥í•œ ê³ ìœ  í”„ë¡œí•„ ìˆ˜ í™•ì¸
        available_profiles = len(profile_groups)
        print(f"\nğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ê³ ìœ  í”„ë¡œí•„ ìˆ˜: {available_profiles}ê°œ")

        if available_profiles < sample_size:
            print(f"âš ï¸  ê³ ìœ  í”„ë¡œí•„ ìˆ˜({available_profiles})ê°€ ìƒ˜í”Œ í¬ê¸°({sample_size})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤.")
            print(f"âš ï¸  {available_profiles}ê°œ í”„ë¡œí•„ì—ì„œ ê°ê° 1ê°œì”© ì„ íƒí•©ë‹ˆë‹¤.")
            target_profiles = available_profiles
        else:
            target_profiles = sample_size

        print(f"ğŸ¯ ëª©í‘œ: {target_profiles}ê°œ ê³ ìœ  í”„ë¡œí•„ì—ì„œ ê°ê° 1ê°œ ì¿¼ë¦¬ì”© ì„ íƒ")

        # 3. ëœë¤í•˜ê²Œ í”„ë¡œí•„ ì„ íƒ
        profile_hashes = list(profile_groups.keys())
        selected_profile_hashes = random.sample(profile_hashes, target_profiles)

        print(f"âœ… ì„ íƒëœ í”„ë¡œí•„:")
        for hash_key in selected_profile_hashes:
            major = profile_info[hash_key]['major']
            print(f"  {hash_key} ({major})")

        # 4. ê° ì„ íƒëœ í”„ë¡œí•„ì—ì„œ 1ê°œ ì¿¼ë¦¬ë§Œ ëœë¤ ì„ íƒ
        selected_queries = []
        for profile_hash in selected_profile_hashes:
            profile_queries = profile_groups[profile_hash]
            selected_query = random.sample(profile_queries, 1)[0]
            selected_queries.append(selected_query)

            major = profile_info[profile_hash]['major']
            print(f"  {profile_hash} ({major}): {len(profile_queries)}ê°œ ì¤‘ 1ê°œ ì„ íƒ")

        print(f"ğŸ‰ ìµœì¢… ìƒ˜í”Œë§ ê²°ê³¼: {len(selected_queries)}ê°œ ì¿¼ë¦¬ ì„ íƒ (ì„œë¡œ ë‹¤ë¥¸ {len(selected_queries)}ëª…ì˜ ì‚¬ìš©ì)")

        # 5. ì„ íƒëœ ì¿¼ë¦¬ì˜ ì „ê³µ ë¶„í¬ í™•ì¸ (ì°¸ê³ ìš©)
        final_major_dist = defaultdict(int)
        for query in selected_queries:
            major = query.get('user_profile', {}).get('major', 'unknown')
            final_major_dist[major] += 1

        print(f"ğŸ“Š ìµœì¢… ì „ê³µ ë¶„í¬ (ì°¸ê³ ìš©):")
        for major, count in final_major_dist.items():
            print(f"  {major}: {count}ê°œ")

        return selected_queries

    def _random_sampling(self, queries: List[Dict[str, Any]], sample_size: int) -> List[Dict[str, Any]]:
        """ë‹¨ìˆœ ëœë¤ ìƒ˜í”Œë§"""
        return random.sample(queries, sample_size)


def generate_reproducible_seed(config_dict: Dict[str, Any]) -> int:
    """ì‹¤í—˜ ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ì‹œë“œ ìƒì„±"""

    # ì„¤ì •ì„ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ í•´ì‹œ ìƒì„±
    config_str = json.dumps(config_dict, sort_keys=True)
    hash_object = hashlib.md5(config_str.encode())

    # í•´ì‹œì˜ ì²« 8ìë¦¬ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
    seed = int(hash_object.hexdigest()[:8], 16)
    return seed % 100000  # 0-99999 ë²”ìœ„ë¡œ ì œí•œ


def analyze_sample_distribution(
    original_queries: List[Dict[str, Any]],
    sampled_queries: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """ìƒ˜í”Œë§ ê²°ê³¼ì˜ ë¶„í¬ ë¶„ì„ (ê³ ìœ  í”„ë¡œí•„ ê¸°ë°˜)"""

    def get_profile_distribution(queries):
        # ì„ì‹œ ìƒ˜í”ŒëŸ¬ ì¸ìŠ¤í„´ìŠ¤ë¡œ í•´ì‹œ ìƒì„± í•¨ìˆ˜ ì‚¬ìš©
        temp_sampler = StratifiedSampler()

        profile_hashes = []
        majors = []
        gt_counts = []

        for query in queries:
            user_profile = query.get('user_profile', {})
            profile_hash = temp_sampler._generate_profile_hash(user_profile)
            major = user_profile.get('major', 'unknown')
            gt_count = len(query.get('ground_truth_docs', []))

            profile_hashes.append(profile_hash)
            majors.append(major)
            gt_counts.append(gt_count)

        return {
            'unique_profiles': len(set(profile_hashes)),
            'major_distribution': {major: majors.count(major) for major in set(majors)},
            'gt_count_stats': {
                'mean': sum(gt_counts) / len(gt_counts) if gt_counts else 0,
                'min': min(gt_counts) if gt_counts else 0,
                'max': max(gt_counts) if gt_counts else 0
            }
        }

    original_stats = get_profile_distribution(original_queries)
    sampled_stats = get_profile_distribution(sampled_queries)

    return {
        'original_count': len(original_queries),
        'sampled_count': len(sampled_queries),
        'sampling_ratio': len(sampled_queries) / len(original_queries),
        'original_distribution': original_stats,
        'sampled_distribution': sampled_stats
    }