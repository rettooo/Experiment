#!/usr/bin/env python3
"""
Ground Truth CSV â†’ JSONL ë³€í™˜ ìœ í‹¸ë¦¬í‹°

ìƒˆë¡œìš´ Ground Truth CSV íŒŒì¼ì„ ë°›ì•˜ì„ ë•Œ
ê¸°ì¡´ JSONL í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python utils/gt_converter.py input.csv output.jsonl

CSV í˜•ì‹ (ì˜ˆìƒ):
    query_id,query_text,ground_truth_doc_ids,user_profile_data,...

JSONL í˜•ì‹:
    {"query": "...", "ground_truth_docs": ["doc1", "doc2"], "user_profile": {...}, "metadata": {...}}
"""

import csv
import json
import argparse
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import pandas as pd


class GTConverter:
    """Ground Truth CSVë¥¼ JSONLë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.required_columns = [
            'query',  # ì¿¼ë¦¬ í…ìŠ¤íŠ¸
            'ground_truth_docs'  # Ground Truth ë¬¸ì„œ IDë“¤
        ]

        # ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë ¨ ì»¬ëŸ¼ë“¤ (ì„ íƒì‚¬í•­)
        self.profile_columns = [
            'major',           # ì „ê³µ
            'interest_job',    # ê´€ì‹¬ ì§ë¬´
            'courses',         # ìˆ˜ê°• ì´ë ¥
            'certification',   # ìê²©ì¦
            'club_activities'  # ë™ì•„ë¦¬/ëŒ€ì™¸í™œë™
        ]

        # ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ë“¤ (ì„ íƒì‚¬í•­)
        self.metadata_columns = [
            'gt_id',           # GT ID
            'company_name',    # íšŒì‚¬ëª…
            'job_title',       # ì±„ìš©ê³µê³  ì œëª©
            'url',            # ì±„ìš©ê³µê³  URL
            'rec_idx',        # ì±„ìš©ê³µê³  ì¸ë±ìŠ¤
            'alternative_query'  # ëŒ€ì²´ ì¿¼ë¦¬
        ]

    def detect_csv_format(self, csv_path: str) -> Dict[str, str]:
        """CSV íŒŒì¼ì˜ ì»¬ëŸ¼ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ë§¤í•‘ ì •ë³´ ë°˜í™˜"""
        try:
            # ì²« ëª‡ ì¤„ë§Œ ì½ì–´ì„œ ì»¬ëŸ¼ êµ¬ì¡° íŒŒì•…
            df = pd.read_csv(csv_path, nrows=5)
            columns = df.columns.tolist()

            print(f"ğŸ“‹ CSV íŒŒì¼ ì»¬ëŸ¼ë“¤: {columns}")

            # ì»¬ëŸ¼ ë§¤í•‘ ìë™ ê°ì§€
            column_mapping = {}

            # ì¿¼ë¦¬ ì»¬ëŸ¼ ê°ì§€
            query_candidates = ['query', 'query_text', 'question', 'user_input']
            for col in columns:
                if any(candidate.lower() in col.lower() for candidate in query_candidates):
                    column_mapping['query'] = col
                    break

            # Ground Truth ì»¬ëŸ¼ ê°ì§€
            gt_candidates = ['ground_truth', 'gt_docs', 'relevant_docs', 'answer_docs']
            for col in columns:
                if any(candidate.lower() in col.lower() for candidate in gt_candidates):
                    column_mapping['ground_truth_docs'] = col
                    break

            # ê¸°íƒ€ ì»¬ëŸ¼ë“¤ ìë™ ë§¤í•‘
            for target_col in self.profile_columns + self.metadata_columns:
                for csv_col in columns:
                    if target_col.lower() in csv_col.lower():
                        column_mapping[target_col] = csv_col
                        break

            print(f"ğŸ” ìë™ ê°ì§€ëœ ì»¬ëŸ¼ ë§¤í•‘: {column_mapping}")
            return column_mapping

        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def interactive_column_mapping(self, csv_path: str) -> Dict[str, str]:
        """ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ì—¬ ì»¬ëŸ¼ ë§¤í•‘ ì„¤ì •"""
        auto_mapping = self.detect_csv_format(csv_path)

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        final_mapping = {}

        # ì¿¼ë¦¬ ì»¬ëŸ¼ ë§¤í•‘
        if 'query' in auto_mapping:
            query_col = auto_mapping['query']
            confirm = input(f"ì¿¼ë¦¬ ì»¬ëŸ¼ìœ¼ë¡œ '{query_col}'ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
            if confirm == 'y':
                final_mapping['query'] = query_col
            else:
                query_col = input("ì¿¼ë¦¬ ì»¬ëŸ¼ëª…ì„ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”: ")
                final_mapping['query'] = query_col
        else:
            query_col = input("ì¿¼ë¦¬ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì»¬ëŸ¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            final_mapping['query'] = query_col

        # Ground Truth ì»¬ëŸ¼ ë§¤í•‘
        if 'ground_truth_docs' in auto_mapping:
            gt_col = auto_mapping['ground_truth_docs']
            confirm = input(f"Ground Truth ì»¬ëŸ¼ìœ¼ë¡œ '{gt_col}'ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
            if confirm == 'y':
                final_mapping['ground_truth_docs'] = gt_col
            else:
                gt_col = input("Ground Truth ë¬¸ì„œ ID ì»¬ëŸ¼ëª…ì„ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”: ")
                final_mapping['ground_truth_docs'] = gt_col
        else:
            gt_col = input("Ground Truth ë¬¸ì„œ IDê°€ ìˆëŠ” ì»¬ëŸ¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            final_mapping['ground_truth_docs'] = gt_col

        # ì„ íƒì  ì»¬ëŸ¼ë“¤ ë§¤í•‘
        print("\nğŸ“ ì„ íƒì  ì»¬ëŸ¼ë“¤ì„ ë§¤í•‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ìŠ¤í‚µí•˜ë ¤ë©´ Enter)")
        for col in self.profile_columns + self.metadata_columns:
            if col in auto_mapping:
                csv_col = auto_mapping[col]
                confirm = input(f"{col} â†’ '{csv_col}' ë§¤í•‘ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n/Enter=ìŠ¤í‚µ): ").lower()
                if confirm == 'y':
                    final_mapping[col] = csv_col
            else:
                csv_col = input(f"{col} ì»¬ëŸ¼ëª… (Enter=ìŠ¤í‚µ): ")
                if csv_col.strip():
                    final_mapping[col] = csv_col

        return final_mapping

    def parse_list_field(self, value: Any) -> List[str]:
        """ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ í•„ë“œë¥¼ íŒŒì‹± (ì‰¼í‘œ êµ¬ë¶„, JSON ë°°ì—´ ë“±)"""
        if pd.isna(value) or value is None or value == '':
            return []

        if isinstance(value, str):
            # JSON ë°°ì—´ í˜•íƒœì¸ì§€ í™•ì¸
            value = value.strip()
            if value.startswith('[') and value.endswith(']'):
                try:
                    return json.loads(value)
                except json.JSONDecodeError:
                    pass

            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ë“¤
            return [item.strip() for item in value.split(',') if item.strip()]

        elif isinstance(value, list):
            return [str(item).strip() for item in value if str(item).strip()]

        else:
            return [str(value).strip()] if str(value).strip() else []

    def convert_row(self, row: Dict[str, Any], column_mapping: Dict[str, str]) -> Optional[Dict[str, Any]]:
        """CSV í•œ í–‰ì„ JSONL í˜•íƒœë¡œ ë³€í™˜"""
        try:
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if 'query' not in column_mapping or 'ground_truth_docs' not in column_mapping:
                raise ValueError("í•„ìˆ˜ ì»¬ëŸ¼(query, ground_truth_docs)ì´ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            # ê¸°ë³¸ êµ¬ì¡° ìƒì„±
            jsonl_row = {
                "query": str(row[column_mapping['query']]).strip(),
                "ground_truth_docs": self.parse_list_field(row[column_mapping['ground_truth_docs']])
            }

            # ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
            user_profile = {}
            for field in self.profile_columns:
                if field in column_mapping and column_mapping[field] in row:
                    value = row[column_mapping[field]]
                    if field in ['interest_job', 'courses', 'certification', 'club_activities']:
                        user_profile[field] = self.parse_list_field(value)
                    else:
                        user_profile[field] = str(value).strip() if not pd.isna(value) else ""

            if user_profile:
                jsonl_row["user_profile"] = user_profile

            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {}
            for field in self.metadata_columns:
                if field in column_mapping and column_mapping[field] in row:
                    value = row[column_mapping[field]]
                    if not pd.isna(value):
                        metadata[field] = str(value).strip()

            if metadata:
                jsonl_row["metadata"] = metadata

            return jsonl_row

        except Exception as e:
            print(f"âš ï¸  í–‰ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def convert_csv_to_jsonl(self, csv_path: str, jsonl_path: str, column_mapping: Optional[Dict[str, str]] = None):
        """CSV íŒŒì¼ì„ JSONLë¡œ ë³€í™˜"""

        if not Path(csv_path).exists():
            raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

        # ì»¬ëŸ¼ ë§¤í•‘ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ëŒ€í™”í˜•ìœ¼ë¡œ ì„¤ì •
        if not column_mapping:
            print("ğŸ”§ ì»¬ëŸ¼ ë§¤í•‘ì„ ì„¤ì •í•©ë‹ˆë‹¤...")
            column_mapping = self.interactive_column_mapping(csv_path)

        print(f"ğŸ“‚ ë³€í™˜ ì‹œì‘: {csv_path} â†’ {jsonl_path}")
        print(f"ğŸ—ºï¸  ì‚¬ìš©í•  ì»¬ëŸ¼ ë§¤í•‘: {column_mapping}")

        # CSV ì½ê¸° ë° ë³€í™˜
        converted_count = 0
        error_count = 0

        try:
            df = pd.read_csv(csv_path)

            with open(jsonl_path, 'w', encoding='utf-8') as f:
                for idx, row in df.iterrows():
                    jsonl_row = self.convert_row(row.to_dict(), column_mapping)

                    if jsonl_row:
                        f.write(json.dumps(jsonl_row, ensure_ascii=False) + '\n')
                        converted_count += 1
                    else:
                        error_count += 1

                    if (idx + 1) % 100 == 0:
                        print(f"ì§„í–‰ë¥ : {idx + 1}/{len(df)} í–‰ ì²˜ë¦¬ì™„ë£Œ")

            print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
            print(f"   ğŸ“Š ì„±ê³µ: {converted_count}ê°œ")
            print(f"   âŒ ì‹¤íŒ¨: {error_count}ê°œ")
            print(f"   ğŸ“ ì¶œë ¥ íŒŒì¼: {jsonl_path}")

        except Exception as e:
            print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise

    def validate_jsonl(self, jsonl_path: str) -> bool:
        """ìƒì„±ëœ JSONL íŒŒì¼ì˜ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            print(f"ğŸ” JSONL íŒŒì¼ ê²€ì¦ ì¤‘: {jsonl_path}")

            total_lines = 0
            valid_lines = 0
            sample_entries = []

            with open(jsonl_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    total_lines += 1
                    try:
                        entry = json.loads(line.strip())

                        # í•„ìˆ˜ í•„ë“œ í™•ì¸
                        if 'query' in entry and 'ground_truth_docs' in entry:
                            valid_lines += 1

                            # ì²˜ìŒ 3ê°œ í•­ëª©ì„ ìƒ˜í”Œë¡œ ì €ì¥
                            if len(sample_entries) < 3:
                                sample_entries.append(entry)

                    except json.JSONDecodeError:
                        print(f"âš ï¸  {i+1}ë²ˆì§¸ ì¤„ JSON íŒŒì‹± ì‹¤íŒ¨")

            print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼:")
            print(f"   ì „ì²´ ë¼ì¸: {total_lines}")
            print(f"   ìœ íš¨ ë¼ì¸: {valid_lines}")
            print(f"   ìœ íš¨ìœ¨: {valid_lines/total_lines*100:.1f}%")

            # ìƒ˜í”Œ ì¶œë ¥
            if sample_entries:
                print(f"\nğŸ“ ìƒ˜í”Œ í•­ëª©ë“¤:")
                for i, entry in enumerate(sample_entries, 1):
                    print(f"   {i}. ì¿¼ë¦¬: {entry['query'][:50]}...")
                    print(f"      GT ë¬¸ì„œ ìˆ˜: {len(entry['ground_truth_docs'])}")
                    if 'user_profile' in entry:
                        print(f"      ì‚¬ìš©ì í”„ë¡œí•„: {list(entry['user_profile'].keys())}")

            return valid_lines == total_lines

        except Exception as e:
            print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(
        description='Ground Truth CSVë¥¼ JSONL í˜•íƒœë¡œ ë³€í™˜',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
    # ëŒ€í™”í˜• ë³€í™˜
    python utils/gt_converter.py input.csv output.jsonl

    # ì»¬ëŸ¼ ë§¤í•‘ ì‚¬ì „ ì •ì˜
    python utils/gt_converter.py input.csv output.jsonl --mapping query:query_text,ground_truth_docs:gt_docs

    # ê²€ì¦ë§Œ ì‹¤í–‰
    python utils/gt_converter.py --validate output.jsonl
        """
    )

    parser.add_argument('input_file', nargs='?', help='ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('output_file', nargs='?', help='ì¶œë ¥ JSONL íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--mapping', help='ì»¬ëŸ¼ ë§¤í•‘ (ì˜ˆ: query:query_text,ground_truth_docs:gt_docs)')
    parser.add_argument('--validate', help='JSONL íŒŒì¼ ê²€ì¦ë§Œ ì‹¤í–‰')

    args = parser.parse_args()

    converter = GTConverter()

    # ê²€ì¦ ëª¨ë“œ
    if args.validate:
        if converter.validate_jsonl(args.validate):
            print("âœ… ê²€ì¦ ì„±ê³µ!")
            sys.exit(0)
        else:
            print("âŒ ê²€ì¦ ì‹¤íŒ¨!")
            sys.exit(1)

    # ë³€í™˜ ëª¨ë“œ
    if not args.input_file or not args.output_file:
        parser.print_help()
        sys.exit(1)

    # ì»¬ëŸ¼ ë§¤í•‘ íŒŒì‹±
    column_mapping = None
    if args.mapping:
        column_mapping = {}
        for pair in args.mapping.split(','):
            if ':' in pair:
                key, value = pair.split(':', 1)
                column_mapping[key.strip()] = value.strip()

    try:
        # ë³€í™˜ ì‹¤í–‰
        converter.convert_csv_to_jsonl(args.input_file, args.output_file, column_mapping)

        # ìë™ ê²€ì¦
        print("\nğŸ” ìë™ ê²€ì¦ ì‹¤í–‰...")
        if converter.validate_jsonl(args.output_file):
            print("ğŸ‰ ë³€í™˜ ë° ê²€ì¦ ì™„ë£Œ!")
        else:
            print("âš ï¸  ë³€í™˜ì€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì¼ë¶€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()