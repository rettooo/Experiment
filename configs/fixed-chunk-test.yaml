# 🎯 Career-HY RAG Fixed Chunking 실험 설정
# Fixed Size Chunking (고정 크기 청킹) 전략 테스트

experiment_name: "fixed-chunk-test"
description: "Fixed Size Chunking (600/100) 전략 - ChromaDB 검색"
output_dir: "results"

# 임베딩 설정
embedder:
  type: "openai"
  model_name: "text-embedding-ada-002"
  batch_size: 5

# 청킹 설정 - Fixed Size Chunking
chunker:
  type: "fixed"
  chunk_size: 600
  chunk_overlap: 100

# 검색 설정
retriever:
  type: "chroma"
  collection_name: "job-postings-fixed-chunk"
  persist_directory: "/tmp/chroma_fixed_chunk"
  top_k: 10

# LLM 설정 (실제 서비스와 동일)
llm:
  type: "openai"
  model_name: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 1000

# 응답 생성기 설정 (실제 서비스와 동일)
response_generator:
  type: "careerhy"
  model_name: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 2000

# 데이터 설정
data:
  pdf_prefix: "initial-dataset/pdf/"
  json_prefix: "initial-dataset/json/"
  test_queries_path: "data/test_queries_fixed.jsonl"
  data_version: "v1"  # S3 데이터 버전 (데이터 변경 시 v2, v3으로 증가)

# 이중 평가 설정
evaluation:
  # 검색 성능 평가 (전체 575개 쿼리)
  retrieval:
    target: "all"
    metrics: ["recall@k", "precision@k", "mrr", "map", "ndcg@k"]
    k_values: [1, 3, 5, 10]

  # 생성 품질 평가 (15개 고유 프로필 샘플)
  generation:
    target: "sample"
    sample_size: 15
    sample_strategy: "profile_based"
    sample_seed: null

# LangSmith 고품질 정성 평가 (선택사항)
langsmith:
  enabled: true  # LangSmith 활성화 - LLM-as-Judge 정성 평가
  project_name: "career-hy-fixed-chunk"
  judge_model: "gpt-4o-mini"
  
  # LangSmith 추적용 태그
  tags:
    - "fixed-chunking"
    - "chunk-600-100"
    - "chroma"
    - "ada-002"
    - "gpt-4o-mini"

  # 4가지 정성 평가 지표
  metrics:
    - "recommendation_quality"    # 추천 품질 전반
    - "personalization_score"     # 개인화 수준
    - "response_helpfulness"      # 도움이 되는 정도
    - "profile_alignment"         # 프로필 일치도

  # 비용 최적화 설정
  max_concurrency: 3
  evaluation_timeout: 300