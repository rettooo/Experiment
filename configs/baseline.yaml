# 🎯 Career-HY RAG 베이스라인 실험 설정
# 실제 서비스와 완전히 동일한 로직으로 성능 측정

experiment_name: "baseline"
description: "실제 Career-HY 서비스와 동일한 설정 - LangChain structured_output, 인덱스 기반 추천"
output_dir: "results"

# 임베딩 설정 (실제 서비스와 동일)
embedder:
  type: "openai"
  model_name: "text-embedding-ada-002"
  batch_size: 5

# 청킹 설정 (실제 서비스: 청킹 사용 안함)
chunker:
  type: "no_chunk"
  chunk_size: null
  chunk_overlap: null

# 검색 설정 (실제 서비스와 동일)
retriever:
  type: "chroma"
  collection_name: "job-postings-baseline"
  persist_directory: "/tmp/chroma_baseline"
  top_k: 10

# LLM 설정 (실제 서비스와 동일)
llm:
  type: "openai"
  model_name: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 1000

# 응답 생성기 설정 (실제 서비스와 동일)
response_generator:
  type: "careerhy"
  model_name: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 2000

# 데이터 설정
data:
  pdf_prefix: "initial-dataset/pdf/"
  json_prefix: "initial-dataset/json/"
  test_queries_path: "data/test_queries_fixed.jsonl"
  data_version: "v1"  # S3 데이터 버전 (데이터 변경 시 v2, v3으로 증가)

# 이중 평가 설정
evaluation:
  # 검색 성능 평가 (전체 575개 쿼리)
  retrieval:
    target: "all"
    metrics: ["recall@k", "precision@k", "mrr", "map", "ndcg@k"]
    k_values: [1, 3, 5, 10]

  # 생성 품질 평가 (15개 고유 프로필 샘플)
  generation:
    target: "sample"
    sample_size: 15
    sample_strategy: "profile_based"
    sample_seed: null

# LangSmith 고품질 정성 평가 (선택사항)
langsmith:
  enabled: true  # LangSmith 활성화 - LLM-as-Judge 정성 평가
  project_name: "career-hy-baseline"
  judge_model: "gpt-4o-mini"
  
  # LangSmith 추적용 태그
  tags:
    - "baseline"
    - "no-chunk"
    - "chroma"
    - "ada-002"
    - "gpt-4o-mini"

  # 4가지 정성 평가 지표
  metrics:
    - "recommendation_quality"    # 추천 품질 전반
    - "personalization_score"     # 개인화 수준
    - "response_helpfulness"      # 도움이 되는 정도
    - "profile_alignment"         # 프로필 일치도

  # 비용 최적화 설정
  max_concurrency: 3
  evaluation_timeout: 300