"""
Career-HY ìŠ¤íƒ€ì¼ ì‘ë‹µ ìƒì„±ê¸°

ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ìƒì„±
LangChain with_structured_output ë°©ì‹ ì‚¬ìš©
"""

import json
import logging
from typing import Dict, List, Any, Optional
from langchain_openai import ChatOpenAI

from core.interfaces.response_generator import (
    BaseResponseGenerator,
    GeneratedResponse,
    RecommendedJob,
    JobRecommendationResponse,
)
from services.prompt_builder import CareerHYPromptBuilder

logger = logging.getLogger(__name__)


class CareerHYResponseGenerator(BaseResponseGenerator):
    """Career-HY ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ì‘ë‹µ ìƒì„± (LangChain structured_output ë°©ì‹)"""

    def __init__(
        self,
        model_name: str = "gpt-4o-mini",
        temperature: float = 0.7,
        max_tokens: int = 1000,
    ):
        # LangChain ChatOpenAI ì´ˆê¸°í™” (ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼)
        self.llm = ChatOpenAI(
            model=model_name, temperature=temperature, max_tokens=max_tokens
        )
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.prompt_builder = CareerHYPromptBuilder()

    async def generate(
        self,
        query: str,
        retrieved_docs: List[Dict[str, Any]],
        user_profile: Dict[str, Any],
        chat_history: Optional[List[Dict[str, Any]]] = None,
        config_tags: List[str] = None,  # ì¶”ê°€
    ) -> GeneratedResponse:
        """
        ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ìƒì„± (LangChain structured_output)

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            retrieved_docs: ê²€ìƒ‰ëœ ì±„ìš©ê³µê³  ë¬¸ì„œë“¤
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„
            chat_history: ëŒ€í™” ì´ë ¥

        Returns:
            GeneratedResponse: ìƒì„±ëœ êµ¬ì¡°í™”ëœ ì‘ë‹µ
        """

        try:
            # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼)
            prompt = self.prompt_builder.build_recommendation_prompt(
                query=query,
                retrieved_docs=retrieved_docs,
                user_profile=user_profile,
                chat_history=chat_history,
            )

            logger.debug(f"Generated prompt length: {len(prompt)} characters")

            # 2. ë™ì  íƒœê·¸ ìƒì„±
            tags = (config_tags or []) + [
                "response-generation",
                f"retrieved-docs-{len(retrieved_docs)}",
            ]
            # 2. LangChain with_structured_output ë°©ì‹ (ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼)
            structured_llm = self.llm.with_structured_output(JobRecommendationResponse)
            result: JobRecommendationResponse = await structured_llm.ainvoke(
                prompt, config={"tags": tags}
            )

            logger.info(f"ğŸ¤– LLM Structured Output ê²°ê³¼:")
            logger.info(
                f"  - recommended_job_indices: {result.recommended_job_indices}"
            )
            logger.info(f"  - overall_advice ê¸¸ì´: {len(result.overall_advice)}")
            logger.info(
                f"  - recommendation_reasons ê°œìˆ˜: {len(result.recommendation_reasons)}"
            )
            logger.info(f"  - practical_tips ê¸¸ì´: {len(result.practical_tips)}")

            # 3. ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë³€í™˜
            return self._convert_to_experiment_response(result, retrieved_docs)

        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            # í´ë°±: ê¸°ë³¸ ì‘ë‹µ ìƒì„±
            return self._create_fallback_response(query, retrieved_docs)

    def _convert_to_experiment_response(
        self,
        structured_result: JobRecommendationResponse,
        retrieved_docs: List[Dict[str, Any]],
    ) -> GeneratedResponse:
        """
        LangChain structured_output ê²°ê³¼ë¥¼ ì‹¤í—˜ìš© ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        (ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ë¡œì§)
        """

        # ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸ ìƒì„± (ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼)
        if structured_result.recommended_job_indices:
            # ì±„ìš©ê³µê³  ì¶”ì²œì´ ìˆëŠ” ê²½ìš°
            content = f"""
{structured_result.overall_advice}

ì‹¤ë¬´ íŒ:
{structured_result.practical_tips}
""".strip()
        else:
            # ì¼ë°˜ ìƒë‹´/ì¡°ì–¸ì¸ ê²½ìš° (ì±„ìš©ê³µê³  ì¶”ì²œ ì—†ìŒ)
            content = f"""
{structured_result.overall_advice}

{structured_result.practical_tips}
""".strip()

        # ì¶”ì²œëœ ì±„ìš©ê³µê³  íŒŒì‹± (ì¸ë±ìŠ¤ â†’ ì‹¤ì œ JobPosting ê°ì²´)
        recommended_jobs = []

        for i, job_index in enumerate(structured_result.recommended_job_indices):
            try:
                # 1-based indexë¥¼ 0-basedë¡œ ë³€í™˜
                doc_index = job_index - 1

                if 0 <= doc_index < len(retrieved_docs):
                    doc = retrieved_docs[doc_index]
                    metadata = doc.get("metadata", {})

                    # ì¶”ì²œ ì´ìœ  ê°€ì ¸ì˜¤ê¸° (ì¸ë±ìŠ¤ì— ë§ì¶°)
                    reason = ""
                    if i < len(structured_result.recommendation_reasons):
                        reason = structured_result.recommendation_reasons[i]

                    recommended_job = RecommendedJob(
                        rec_idx=metadata.get("rec_idx"),
                        title=metadata.get(
                            "title", metadata.get("post_title", "ì œëª© ì—†ìŒ")
                        ),
                        url=metadata.get("url") or metadata.get("detail_url", ""),
                        deadline=metadata.get("deadline"),
                        start_date=metadata.get("start_date"),
                        crawling_time=metadata.get("crawling_time"),
                        recommendation_reason=reason,
                    )
                    recommended_jobs.append(recommended_job)

                    logger.info(f"âœ… ì¶”ì²œ ê³µê³  {job_index}: {recommended_job.title}")
                else:
                    logger.warning(
                        f"âŒ ì˜ëª»ëœ ì¶”ì²œ ì¸ë±ìŠ¤: {job_index} (ë²”ìœ„: 1-{len(retrieved_docs)})"
                    )

            except Exception as e:
                logger.warning(f"Failed to process job recommendation {job_index}: {e}")
                continue

        return GeneratedResponse(content=content, recommended_jobs=recommended_jobs)

    def _create_fallback_response(
        self, query: str, retrieved_docs: List[Dict[str, Any]]
    ) -> GeneratedResponse:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""

        content = f"""ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  '{query}'ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ì´ ì–´ë ¤ì› ìŠµë‹ˆë‹¤.
í•˜ì§€ë§Œ ê²€ìƒ‰ëœ ì±„ìš©ê³µê³ ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ì„±ì´ ë†’ì€ ê³µê³ ë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤."""

        # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ìƒìœ„ 3ê°œë¥¼ ê¸°ë³¸ ì¶”ì²œìœ¼ë¡œ ì œê³µ
        recommended_jobs = []
        for i, doc in enumerate(retrieved_docs[:3]):
            metadata = doc.get("metadata", {})
            recommended_job = RecommendedJob(
                rec_idx=metadata.get("rec_idx", f"fallback_{i}"),
                title=metadata.get(
                    "title", metadata.get("post_title", f"ì±„ìš©ê³µê³  {i+1}")
                ),
                url=metadata.get("url", ""),
                deadline=metadata.get("deadline"),
                recommendation_reason=f"ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ {i+1}ë²ˆì§¸ë¡œ ê´€ë ¨ì„±ì´ ë†’ì€ ê³µê³ ì…ë‹ˆë‹¤.",
            )
            recommended_jobs.append(recommended_job)

        return GeneratedResponse(content=content, recommended_jobs=recommended_jobs)
